{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6986e1-15d3-47e4-9a7f-af820a4b7973",
   "metadata": {},
   "source": [
    "# NBA MVP Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0d1e3-b11d-428b-b991-e7f647ae32ac",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Import data/modules](#import-data)\n",
    "* [Exploratory Data Analysis](#eda)\n",
    "* [Preprocessing](#preprocessing)\n",
    "* [Modeling](#modeling)\n",
    "* [Forecasting 2022 MVP](#forecasting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83ab47-72b0-49ef-8e16-60206f3da267",
   "metadata": {},
   "source": [
    "## Import data/modules <a class=\"anchor\" id=\"import-data\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e0757c-fed4-4d6e-a362-7da8e468f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#essentials\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "#tools/metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "\n",
    "#modeling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "#pandas show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#%run ./__init__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913f787-dddb-4c05-8939-b3132f1b8b67",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf11118-0cf3-4ced-b56d-869b7f410cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = os.path.dirname(os.getcwd()) + '/data' + '/master_table.csv'\n",
    "#master_table = pd.read_csv(data_path)\n",
    "master_table = pd.read_csv(\"D:\\\\Github\\\\Capstone-project\\\\Data folder\\\\final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b6291-fdcd-4e21-81d2-168aefc5a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed638b5f-3dca-44dc-92fb-c62609d5e20e",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis <a class=\"anchor\" id=\"eda\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ed657-71d7-401f-8c88-81f8b3afdb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6581ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(master_table.columns)))\n",
    "print(len(list(master_table.columns[(master_table. dtypes == 'float64') | (master_table. dtypes == 'int64') ])))\n",
    "print(len(list(master_table.columns[(master_table. dtypes != 'float64') & (master_table. dtypes != 'int64') ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3a20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = list(master_table.columns[(master_table. dtypes == 'float64') | (master_table. dtypes == 'int64') ])\n",
    "print(columns_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a55f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_not_used = list(master_table.columns[(master_table. dtypes != 'float64') & (master_table. dtypes != 'int64') ])\n",
    "print(columns_not_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66a46f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "master_table['year'] = master_table['year'].astype(int)\n",
    "list(master_table['year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cae9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table['prev_year'] = master_table['year']-1\n",
    "master_table[['Player Name', 'season', 'Team','year', 'prev_year','ows', 'dws']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c3adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = master_table[master_table['games']<40]\n",
    "df_to_use = filtered_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (master_table.shape)\n",
    "print(filtered_df.shape)\n",
    "print(df_to_use.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f971fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_to_use, df_to_use , how = 'inner',\n",
    "                     left_on = ['Player Name','year'] ,\n",
    "                     right_on = ['Player Name','prev_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b624a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#master_table = merged_df\n",
    "merged_df['offense'] = merged_df['%Min_y']*merged_df['ORtg_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65990916",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[['%Min_y','ORtg_y', 'offense' ]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = list(merged_df.columns[(merged_df. dtypes == 'float64') | (merged_df. dtypes == 'int64') ])\n",
    "print(columns_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153a9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Unnamed: 0_x_x', 'games_x', 'games_started_x', 'mp_per_g_x', 'fg_per_g_x', 'fga_per_g_x', 'fg2_per_g_x', 'fg2a_per_g_x', 'fg3_per_g_x', 'fg3a_per_g_x', 'ft_per_g_x', 'fta_per_g_x', 'orb_per_g_x', 'drb_per_g_x', 'trb_per_g_x', 'ast_per_g_x', 'stl_per_g_x', 'blk_per_g_x', 'tov_per_g_x', 'pf_per_g_x', 'pts_per_g_x', 'sos_x', 'mp_x', 'fg_x', 'fga_x', 'fg2_x', 'fg2a_x', 'fg3_x', 'fg3a_x', 'ft_x', 'fta_x', 'orb_x', 'drb_x', 'trb_x', 'ast_x', 'stl_x', 'blk_x', 'tov_x', 'pf_x', 'pts_x', 'fg_per_min_x', 'fga_per_min_x', 'fg2_per_min_x', 'fg2a_per_min_x', 'fg3_per_min_x', 'fg3a_per_min_x', 'ft_per_min_x', 'fta_per_min_x', 'trb_per_min_x', 'ast_per_min_x', 'stl_per_min_x', 'blk_per_min_x', 'tov_per_min_x', 'pf_per_min_x', 'pts_per_min_x', 'fg_per_poss_x', 'fga_per_poss_x', 'fg2_per_poss_x', 'fg2a_per_poss_x', 'fg3_per_poss_x', 'fg3a_per_poss_x', 'ft_per_poss_x', 'fta_per_poss_x', 'trb_per_poss_x', 'ast_per_poss_x', 'stl_per_poss_x', 'blk_per_poss_x', 'tov_per_poss_x', 'pf_per_poss_x', 'pts_per_poss_x', 'off_rtg_x', 'def_rtg_x', 'per_x', 'ts_pct_x', 'efg_pct_x', 'fg3a_per_fga_pct_x', 'fta_per_fga_pct_x', 'pprod_x', 'orb_pct_x', 'drb_pct_x', 'trb_pct_x', 'ast_pct_x', 'stl_pct_x', 'blk_pct_x', 'tov_pct_x', 'usg_pct_x', 'ows_x', 'dws_x', 'ws_x', 'ws_per_40_x', 'obpm_x', 'dbpm_x', 'bpm_x', 'Ht_x', 'Wt_x', 'G_x', 'S_x', '%Min_x', 'ORtg_x', '%Poss_x', '%Shots_x', 'eFG%_x', 'TS%_x', 'OR%_x', 'DR%_x', 'ARate_x', 'TORate_x', 'Blk%_x', 'Stl%_x', 'FC/40_x', 'FD/40_x', 'FTRate_x', 'Pct.2_x', '%Pct_x', '%Pct.1_x', 'Unnamed: 0_x_y', 'games_y', 'games_started_y', 'mp_per_g_y', 'fg_per_g_y', 'fga_per_g_y', 'fg2_per_g_y', 'fg2a_per_g_y', 'fg3_per_g_y', 'fg3a_per_g_y', 'ft_per_g_y', 'fta_per_g_y', 'orb_per_g_y', 'drb_per_g_y', 'trb_per_g_y', 'ast_per_g_y', 'stl_per_g_y', 'blk_per_g_y', 'tov_per_g_y', 'pf_per_g_y', 'pts_per_g_y', 'sos_y', 'mp_y', 'fg_y', 'fga_y', 'fg2_y', 'fg2a_y', 'fg3_y', 'fg3a_y', 'ft_y', 'fta_y', 'orb_y', 'drb_y', 'trb_y', 'ast_y', 'stl_y', 'blk_y', 'tov_y', 'pf_y', 'pts_y', 'fg_per_min_y', 'fga_per_min_y', 'fg2_per_min_y', 'fg2a_per_min_y', 'fg3_per_min_y', 'fg3a_per_min_y', 'ft_per_min_y', 'fta_per_min_y', 'trb_per_min_y', 'ast_per_min_y', 'stl_per_min_y', 'blk_per_min_y', 'tov_per_min_y', 'pf_per_min_y', 'pts_per_min_y', 'fg_per_poss_y', 'fga_per_poss_y', 'fg2_per_poss_y', 'fg2a_per_poss_y', 'fg3_per_poss_y', 'fg3a_per_poss_y', 'ft_per_poss_y', 'fta_per_poss_y', 'trb_per_poss_y', 'ast_per_poss_y', 'stl_per_poss_y', 'blk_per_poss_y', 'tov_per_poss_y', 'pf_per_poss_y', 'pts_per_poss_y', 'off_rtg_y', 'def_rtg_y', 'per_y', 'ts_pct_y', 'efg_pct_y', 'fg3a_per_fga_pct_y', 'fta_per_fga_pct_y', 'pprod_y', 'orb_pct_y', 'drb_pct_y', 'trb_pct_y', 'ast_pct_y', 'stl_pct_y', 'blk_pct_y', 'tov_pct_y', 'usg_pct_y', 'ows_y', 'dws_y', 'ws_y', 'ws_per_40_y', 'obpm_y', 'dbpm_y', 'bpm_y', 'Ht_y', 'Wt_y', 'G_y', 'S_y', '%Min_y', 'ORtg_y', '%Poss_y', '%Shots_y', 'eFG%_y', 'TS%_y', 'OR%_y', 'DR%_y', 'ARate_y', 'TORate_y', 'Blk%_y', 'Stl%_y', 'FC/40_y', 'FD/40_y', 'FTRate_y', 'Pct.2_y', '%Pct_y', '%Pct.1_y', 'offense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e359102",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table  = merged_df[columns]\n",
    "print(master_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5227edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#master_table.to_csv('D:\\\\Github\\\\Capstone-project\\\\Data folder\\\\zain_testing.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9699a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table[['%Min_x','ORtg_x', 'offense' ]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dfcbd2-3bc0-4836-8dc6-9eae37355fb9",
   "metadata": {},
   "source": [
    "### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33f759-879c-4d10-994d-1716e5cd9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlations of each features\n",
    "corr_matrix = master_table.corr()\n",
    "\n",
    "#plot heat map\n",
    "mask = np.zeros_like(corr_matrix)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(15, 15))\n",
    "    ax = sns.heatmap(corr_matrix, mask=mask, vmax=.3, square=True,cmap=\"RdYlGn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a641b-823d-43e6-bd2e-fd5db5984a65",
   "metadata": {},
   "source": [
    "### Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a702117f-e89a-4baa-8f3a-aa5c9d10a646",
   "metadata": {},
   "source": [
    "Mutual information describes relationships in terms of uncertainty. The mutual information (MI) between two quantities is a measure of the extent to which knowledge of one quantity reduces uncertainty about the other\n",
    "\n",
    "The least possible mutual information between quantities is 0.0. When MI is zero, the quantities are independent: neither can tell you anything about the other. Conversely, in theory there's no upper bound to what MI can be. In practice though values above 2.0 or so are uncommon. (Mutual information is a logarithmic quantity, so it increases very slowly.)\n",
    "\n",
    "* MI can help you to understand the relative potential of a feature as a predictor of the target, considered by itself.\n",
    "* It's possible for a feature to be very informative when interacting with other features, but not so informative all alone. MI can't detect interactions between features. It is a univariate metric.\n",
    "* The actual usefulness of a feature depends on the model you use it with. A feature is only useful to the extent that its relationship with the target is one your model can learn. Just because a feature has a high MI score doesn't mean your model will be able to do anything with that information. You may need to transform the feature first to expose the association.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951e2fe-0926-4d28-9bea-1ec0f1e31dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ml_scores(df):\n",
    "    X = df.copy()\n",
    "    y = X[\"offense\"]\n",
    "\n",
    "    X.drop('offense', axis=1, inplace=True)\n",
    "\n",
    "    # Label encoding for categoricals\n",
    "    for colname in X.select_dtypes(\"object\"):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "\n",
    "    # All discrete features should now have integer dtypes (double-check this before using MI!)\n",
    "    discrete_features = X.dtypes == int\n",
    "    \n",
    "    mi_scores = mutual_info_regression(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return X, y, mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f72c42-059c-45d3-9978-90be2e97d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#drop columns for mutual information\n",
    "to_drop_mi = ['Rank','Player','Age','year','Tm','team','First','Pts Won','Pts Max','WS','WS/48']\n",
    "master_table_mi = master_table.copy()\n",
    "master_table_mi.drop(to_drop_mi, axis=1, inplace=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3103615e-c54d-47b4-8631-f0fca2eac3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, mi_scores = calculate_ml_scores(df=master_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5a0f7-7edb-48cb-8968-8b8c481888bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mi_scores(scores, figsize):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.barh(width, scores)\n",
    "    \n",
    "    for index, value in enumerate(scores):\n",
    "        plt.text(value +0.005 , index, str(round(value,2)))\n",
    "    \n",
    "    plt.yticks(width, ticks)    \n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "plot_mi_scores(mi_scores, figsize=(14,11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f7ca7-3ef6-4d09-9430-d968114fb046",
   "metadata": {},
   "source": [
    "### Visualize significant features vs. MVP Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b08802-b744-4356-aa1c-c5878e3d50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_win_lose_col(df):\n",
    "    rank_lst = []\n",
    "    for i in list(df['Rank']):\n",
    "        if i == '1':\n",
    "            rank_lst.append('won')\n",
    "        else:\n",
    "            rank_lst.append('lost')\n",
    "    master_table_rank = df.copy()\n",
    "    master_table_rank['Win/Lose'] = rank_lst\n",
    "    return master_table_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb102890-c54d-4b03-aa72-3bbe4fc9dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_vs_share(feature, df):\n",
    "    fig = px.scatter(data_frame = df,\n",
    "               x=feature,\n",
    "               y='Share',\n",
    "               color='Win/Lose',\n",
    "               color_discrete_sequence=['blue','gray'], \n",
    "               hover_data={\n",
    "                   'Win/Lose': False,\n",
    "                   'Player': True, \n",
    "                   'year': True,\n",
    "                   'seed': True,\n",
    "                   'W/L%': True, \n",
    "                   'W': True\n",
    "                   \n",
    "               })\n",
    "    fig.update_layout(height=500,\n",
    "                     title = f\"{feature} vs. MVP share\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e48fb-af76-4784-a48b-11350351888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "features = ['win_shares', \n",
    "            'player_efficiency_rating',\n",
    "            'value_over_replacement_player',\n",
    "            'box_plus_minus',\n",
    "            'offensive_box_plus_minus',\n",
    "            'usage_percentage',\n",
    "            'seed',\n",
    "            'W',\n",
    "            'W/L%',\n",
    "            'PTS']\n",
    "\n",
    "master_table_rank = add_win_lose_col(df=master_table)\n",
    "\n",
    "for feature in features:\n",
    "    show_feature_vs_share(feature=feature, df=master_table_rank)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12222e4-0f46-4e98-a036-71c745eff718",
   "metadata": {},
   "source": [
    "At this point these variables may seem to have somewhat linear relationship with the MVP share metric. It could be valid to consider them as model features as the experiments are conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd883670-5b2c-4689-b316-a9fc635ebc0f",
   "metadata": {},
   "source": [
    "# Preprocessing <a class=\"anchor\" id=\"preprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18746bf0-f39c-43d1-96d9-223225b89162",
   "metadata": {},
   "source": [
    "drop unnecessary or redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d3905-dd3f-43e6-b00d-bb6d594cb889",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "'''\n",
    "\n",
    "#drop columns \n",
    "\n",
    "to_drop = [\n",
    "    'Rank',\n",
    "    'Player',\n",
    "    'Age',\n",
    "    'year',\n",
    "    'Tm',\n",
    "    'team',\n",
    "    'First',\n",
    "    'Pts Won',\n",
    "    'Pts Max',\n",
    "    'WS/48',\n",
    "    'WS',\n",
    "    'MP',\n",
    "    'G',\n",
    "    'W', \n",
    "    'FG%',\n",
    "    '3P%',\n",
    "    'STL', \n",
    "    'BLK',\n",
    "    'three_point_attempt_rate',\n",
    "    'total_rebound_percentage',\n",
    "    'offensive_rebound_percentage',\n",
    "    'block_percentage',\n",
    "    'defensive_rebound_percentage',\n",
    "    'steal_percentage',\n",
    "    'turnover_percentage',\n",
    "    'assist_percentage',\n",
    "    'AST',\n",
    "    'TRB',\n",
    "    #'free_throw_attempt_rate', ######### Experiment\n",
    "    'FT%',\n",
    "    'win_shares', \n",
    "    #'value_over_replacement_player', \n",
    "    'box_plus_minus', \n",
    "    #'offensive_box_plus_minus', \n",
    "    'defensive_box_plus_minus',\n",
    "    'offensive_win_shares', \n",
    "    'defensive_win_shares', \n",
    "    'true_shooting_percentage' \n",
    "]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6690db-de3f-4db4-90ed-3e8dbcb052f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run another Mutual Information Score analysis\n",
    "master_table_mi2 = master_table.copy()\n",
    "master_table_mi2.drop(to_drop, axis=1, inplace=True)\n",
    "X, y, mi_scores2 = calculate_ml_scores(df=master_table_mi2)\n",
    "plot_mi_scores(mi_scores2, figsize=(14,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaee60d-50cb-4a6f-9631-6501a2573a99",
   "metadata": {},
   "source": [
    "## Modeling <a class=\"anchor\" id=\"modeling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b011edd-6e3f-4f4a-bc6e-48948ff039c3",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2ff4c-e042-4b0d-8c2e-eaab83d91acb",
   "metadata": {},
   "source": [
    "test on selected year, train on all other years that weren't selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb67ca-0ff0-4176-9c4a-413064692032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_by_year(year, df, scaling=False):\n",
    "    #test year = selected year, train year = other years outside of selected year\n",
    "    train_df = df[df['year'] != year]\n",
    "    test_df = df[df['year'] == year]\n",
    "    \n",
    "    train_df2 = train_df.copy()\n",
    "    test_df2 = test_df.copy()\n",
    "    \n",
    "    train_df2.drop(to_drop, axis=1, inplace=True)\n",
    "    test_df2.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    if scaling == True:\n",
    "        sc_X = StandardScaler()\n",
    "        sc_y = StandardScaler()\n",
    "        train_df2 = sc_X.fit_transform(train_df2)\n",
    "        test_df2 = sc_y.fit_transform(test_df2)\n",
    "    \n",
    "    X_train = train_df2.copy()\n",
    "    y_train = X_train[\"offense\"]\n",
    "    \n",
    "    X_test = test_df2.copy()\n",
    "    y_test = X_test[\"offense\"]\n",
    "\n",
    "    X_train.drop('offense', axis=1, inplace=True)\n",
    "    cols = X_train.columns\n",
    "    X_test.drop('offense', axis=1, inplace=True)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52275ad2-e765-4dca-9809-51c7680b734f",
   "metadata": {},
   "source": [
    "### Model Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65bc7e9-a4ca-4888-ae7c-de8690fb0a89",
   "metadata": {},
   "source": [
    "train, predict, calculate MAE & R squared, show actual vs. predicted in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f41e1c-84b8-43ce-9fc6-ed991b761b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(regressor, X_train, y_train, X_test, y_test, df, year):\n",
    "    model = regressor\n",
    "    model.fit(X_train, y_train) \n",
    "    predictions = model.predict(X_test)\n",
    "    mae = mean_absolute_error(predictions, y_test)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    mvp_race = df[df['year'] == year]\n",
    "    mvp_race['predicted_offense'] = predictions\n",
    "    mvp_race = mvp_race.sort_values([\"offense\", \"predicted_offense\"], ascending = (False, False))\n",
    "                                    \n",
    "    #actual_winner = mvp_race[mvp_race['offense'] == mvp_race['offense'].max()]['Player']\n",
    "    #predicted_winner = mvp_race[mvp_race['predicted_offense'] == mvp_race['predicted_offense'].max()]['Player']\n",
    "    return model, mae, r2,  mvp_race #, predicted_winner.iloc[0], actual_winner.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783380b-96f0-47d2-876f-d42e44a9e4e8",
   "metadata": {},
   "source": [
    "find average metrics and overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954818f7-83b1-4728-928d-29ccf2193d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2019, 2020, 2021, 2022, 2023]\n",
    "#years = [year for year in range(1980, 2022)]\n",
    "\n",
    "def run_model_average(df, regressor, scaling=False, print_metrics=False):\n",
    "    mae_lst = []\n",
    "    r2_lst = []\n",
    "    predicted_lst = []\n",
    "    actual_lst = []\n",
    "    label_lst =[]\n",
    "    model_lst = []\n",
    "    for year in tqdm(years):\n",
    "        X_train, y_train, X_test, y_test, cols = train_test_split_by_year(year=year, df=df, scaling=False)\n",
    "        model, mae, r2,  mvp_race = run_model(regressor,\n",
    "                                                             X_train,\n",
    "                                                              y_train,\n",
    "                                                              X_test,\n",
    "                                                              y_test,\n",
    "                                                              df=df,\n",
    "                                                              year=year,\n",
    "                                                        )\n",
    "        '''\n",
    "        if predicted_winner == actual_winner:\n",
    "            label = 'correct'\n",
    "        else:\n",
    "            label = 'incorrect'\n",
    "        '''\n",
    "        mae_lst.append(mae)\n",
    "        r2_lst.append(r2)\n",
    "        #predicted_lst.append(predicted_winner)\n",
    "        #actual_lst.append(actual_winner)\n",
    "        #label_lst.append(label)\n",
    "        model_lst.append(model)\n",
    "    d = {\n",
    "    'year': years,\n",
    "    'MAE': mae_lst,\n",
    "    #'R squared': r2_lst,\n",
    "    #'Predicted MVP': predicted_lst,\n",
    "    #'Actual MVP': actual_lst,\n",
    "    #'Label': label_lst\n",
    "    }\n",
    "\n",
    "    summary = pd.DataFrame(d)\n",
    "    #correct_count = summary['Label'].value_counts().iloc[0]\n",
    "    #incorrect_count = summary['Label'].value_counts().iloc[1]\n",
    "    #accuracy = correct_count / (correct_count + incorrect_count)\n",
    "    avg_mae = summary['MAE'].mean()\n",
    "    avg_r2  = summary['R squared'].mean()\n",
    "    \n",
    "    if print_metrics == True:\n",
    "        print(f\"Average MAE: {avg_mae}\")\n",
    "        print(f\"Average R squared: {avg_r2}\")\n",
    "        #print(f\"Prediction accuracy: {accuracy}\")\n",
    "    return avg_mae, avg_r2, summary, model_lst, cols #, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736f7b7-5ef7-405a-94df-085ef36fe65e",
   "metadata": {},
   "source": [
    "### Models\n",
    "* Linear Regression\n",
    "* Random Forest Regressor\n",
    "* XGBoost Regressor\n",
    "* LightGBM Regressor\n",
    "\n",
    "(see parameter_tuning.ipynb for parameter tuning scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "master_table.rename(columns = {'year_x':'year'}, inplace = True) \n",
    "master_table.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d22b588-7570-48aa-8094-fbeb43cfdedf",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08d497-5bc1-40b5-a4a4-e59c0384c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_avg_mae, lr_avg_r2, lr_accuracy, lr_summary, lr_models, cols = run_model_average(df=master_table,\n",
    "                  regressor = LinearRegression(),\n",
    "                 scaling=True,\n",
    "                print_metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6374a601-3488-4a03-903a-c3486489006f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e8b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display feature importance for tree algorithms (RF, XGB, LGBM\n",
    "def avg_feature_importance(models, cols):\n",
    "    lst = []\n",
    "    for model in models:\n",
    "        feature_importance = list(model.feature_importances_)\n",
    "        lst.append(feature_importance)\n",
    "        \n",
    "    df = pd.DataFrame(lst, columns=cols)\n",
    "    mean_features = df.mean()\n",
    "    \n",
    "    #df2 = pd.DataFrame([cols ,mean_features], columns=['Feature', 'Feature Importance'])\n",
    "    df2 = pd.DataFrame([cols ,mean_features]).T\n",
    "    df2 = df2.rename(columns={0:'Feature', 1:'Score'}).sort_values(by='Score', ascending=False)\n",
    "    \n",
    "    #plt.rcParams[\"figure.figsize\"] = (7,4)\n",
    "    plt.title('Feature Importance Score')\n",
    "    sns.barplot(x='Score',\n",
    "                y= 'Feature',\n",
    "               data=df2,\n",
    "                  )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a55b58-d6cd-4175-b4d2-c6a4623342b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_avg_mae, rf_avg_r2, rf_accuracy, rf_summary, rf_models, rf_cols = run_model_average(df=master_table,\n",
    "                  regressor=RandomForestRegressor(n_estimators = 23, \n",
    "                                                  random_state = 0, \n",
    "                                                  max_depth=7, \n",
    "                                                  min_samples_leaf=1,\n",
    "                                                  min_samples_split=2),\n",
    "                print_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8200eafb-80ab-4301-99e9-3539a587eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_feature_importance(models=rf_models, cols=rf_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb883248-fc41-49e9-9ac5-a81863db2ec0",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e80b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BEST MODEL\n",
    "# 16 5, 0.2745\n",
    "\n",
    "xgb_avg_mae, xgb_avg_r2, xgb_accuracy, xgb_summary, xgb_models, xgb_cols = run_model_average(df=master_table,\n",
    "                  regressor = XGBRegressor(n_estimators=16, max_depth=5, learning_rate = 0.2745, subsample=1, colsample_bytree=1),\n",
    "                 scaling=False, print_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f10a0-49eb-44f6-a6d1-e4063dfa062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d41a090-7868-4327-9c68-b920444164c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_feature_importance(models=xgb_models, cols=xgb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c84c9-73ee-4070-96b3-40abccca076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0649bf9b-64d1-4b68-93b7-5807f24d3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export as image\n",
    "dfi.export(xgb_summary,'xgboost_summary.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9814ae0-a058-428c-b7aa-1d624f2f5b66",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce054507-6802-453b-863a-307e74c8c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_avg_mae, lgbm_avg_r2, lgbm_accuracy, lgbm_summary, lgbm_models, lgbm_cols = run_model_average(df=master_table,\n",
    "                  regressor = LGBMRegressor(n_estimators=23,\n",
    "                                            max_depth=4,\n",
    "                                            learning_rate=0.15,\n",
    "                                            num_leaves=28,\n",
    "                                            boosting_type='goss',\n",
    "                                            random_state = 0,\n",
    "                                           ),\n",
    "                 scaling=False, print_metrics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6865f6-00c7-462f-ab7a-f3e595589414",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_feature_importance(models=lgbm_models, cols=lgbm_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef6a82-6005-4e85-9f1f-60418ef0fed9",
   "metadata": {},
   "source": [
    "#### Model Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60731ae7-c3e5-4d81-8c45-1841efe69611",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'Model': ['Linear Regression', 'Random Forest Regressor', 'XGBoost Regressor', 'LGBM Regressor'],\n",
    "    'average MAE': [lr_avg_mae,rf_avg_mae, xgb_avg_mae, lgbm_avg_mae],\n",
    "    'average R squared': [lr_avg_r2,rf_avg_r2, xgb_avg_r2, lgbm_avg_r2],\n",
    "    'accuracy': [lr_accuracy,rf_accuracy, xgb_accuracy, lgbm_accuracy],\n",
    "}\n",
    "model_summary_df = pd.DataFrame(d)\n",
    "model_summary_df.style.highlight_max(subset = ['average R squared', 'accuracy'],\n",
    "                       color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d29125-f525-44bf-b153-f851bc556898",
   "metadata": {},
   "source": [
    "Best Models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6223ede4-05c0-4bc0-8b89-1d9f0f316bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all models in models list have same parameters\n",
    "best_xgb_model = xgb_models[0]\n",
    "best_rf_model = rf_models[0]\n",
    "best_lgbm_model = lgbm_models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec7cb3-e1d5-4565-a752-444aff577b64",
   "metadata": {},
   "source": [
    "### Validate specific year "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fc3713-5dec-4c2d-994e-a794626b6edd",
   "metadata": {},
   "source": [
    "The following function can be used to check details on a specific year's MVP race along with its predictions from the model \n",
    "* see 'Share' for actual share from the specific year's MVP race\n",
    "* see 'predicted_share' for model's predicted share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8eb3c-10cc-4fa6-81f0-e31847aa4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_year(year):\n",
    "    X_train, y_train, X_test, y_test, cols = train_test_split_by_year(year, df=master_table, scaling=False)\n",
    "    model, mae, r2, predicted_winner, actual_winner, mvp_race = run_model(best_xgb_model,\n",
    "                                              X_train, y_train, X_test, y_test, df=master_table, year=year)\n",
    "    # shift column 'Name' to first position\n",
    "    nineth_column = mvp_race.pop('predicted_share')\n",
    "    # first_column) function\n",
    "    mvp_race.insert(8, 'predicted_share', nineth_column)\n",
    "    mvp_race = mvp_race.reset_index(drop=True)\n",
    "\n",
    "    X_test_df = pd.DataFrame(columns=cols, data = X_test)\n",
    "    \n",
    "    print(f'Predicted: {predicted_winner}')\n",
    "    print(f'Actual: {actual_winner}')\n",
    "    avg_feature_importance(models=[model], cols=cols)\n",
    "    \n",
    "    return model, X_test_df, mvp_race #mvp_race.style.highlight_max(subset = ['Share', 'predicted_share'], color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174c6eb-5281-4661-ae9d-a655fee1160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_shap_values(mvp_race, model):\n",
    "    top_candidates = list(mvp_race.head(3)['Player'])\n",
    "\n",
    "    for idx, player in enumerate(top_candidates):\n",
    "        data_for_prediction = mvp_race[mvp_race['Player'] == player]\n",
    "        data_for_prediction = data_for_prediction[list(xgb_cols)]\n",
    "        data_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n",
    "        rank = idx + 1\n",
    "        print(f\"Rank: {rank}: {player}\")\n",
    "\n",
    "        # Create object that can calculate shap values\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        # Calculate Shap values\n",
    "        shap_values = explainer.shap_values(data_for_prediction_array)\n",
    "        shap.initjs()\n",
    "        display(shap.force_plot(explainer.expected_value, shap_values, data_for_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885a665-3fcb-4b6a-832f-02fee7f07faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, X_test_df, mvp_race = validate_year(year=2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f2e62-b14d-462e-86f6-3232f67f554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_shap_values(mvp_race, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83cacf0-5bf9-4310-b506-dc6c169a333d",
   "metadata": {},
   "source": [
    "## Forecasting 2022 MVP <a class=\"anchor\" id=\"forecasting\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1c03f-d2b8-4f93-a11f-e1993bac6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data to be forecasted: 2022 mvp candidates from NBA's MVP ladder\n",
    "data_path_2022 = os.path.dirname(os.getcwd()) + '/data' + '/data_2022.csv'\n",
    "data_2022 = pd.read_csv(data_path_2022)\n",
    "data_2022_cleaned = data_2022.copy()\n",
    "data_2022_cleaned = data_2022_cleaned[list(xgb_cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e94d364-3bf7-4771-be86-efe434cdc2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1cdee-13dd-4659-a71e-93f9c0b010be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train_test(df):\n",
    "    #train; using hitorical data from 1980 - 2021\n",
    "    forecast_X_train_df = df.copy()\n",
    "    forecast_X_train_df.drop(to_drop, axis=1, inplace=True)\n",
    "    forecast_y_train_df = forecast_X_train_df['Share']\n",
    "    forecast_X_train_df.drop(['Share'], axis=1, inplace=True)\n",
    "    \n",
    "    #data to be forecasted: 2022 mvp candidates from NBA's MVP ladder\n",
    "    forecast_X_test_df = data_2022_cleaned\n",
    "    \n",
    "    print(f'Training dataset columns: \\n{list(forecast_X_train_df.columns)} \\n')\n",
    "    print(f'Forecasting dataset columns: \\n{list(forecast_X_test_df.columns)}')\n",
    "    return forecast_X_train_df, forecast_y_train_df, forecast_X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe75e4f7-1b2f-4523-85ea-6214954d66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_forecast_model(regressor):\n",
    "    model = regressor\n",
    "    model.fit(forecast_X_train_df, forecast_y_train_df) \n",
    "    predictions = model.predict(forecast_X_test_df)\n",
    "    \n",
    "    mvp_race_forecast = data_2022.copy()\n",
    "    mvp_race_forecast['Share Prediction'] = predictions\n",
    "    mvp_race_forecast = mvp_race_forecast.sort_values([\"Share Prediction\"], ascending = (False))\n",
    "    \n",
    "    mvp_race_forecast_sub = mvp_race_forecast[[\n",
    "                                                'Player',\n",
    "                                                'Share Prediction',\n",
    "                                                'PTS',\n",
    "                                               'value_over_replacement_player',\n",
    "                                               'seed',\n",
    "                                                'W/L%',\n",
    "                                               'player_efficiency_rating',\n",
    "                                               'win_shares_per_48_minutes',\n",
    "                                                'offensive_box_plus_minus',\n",
    "                                                'usage_percentage',\n",
    "                                            'free_throw_attempt_rate'\n",
    "                                              ]].reset_index(drop=True)\n",
    "    mvp_race_forecast_sub.head()\n",
    "    avg_feature_importance(models=[model], cols=data_2022_cleaned.columns)\n",
    "    return model, mvp_race_forecast_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9036a-4707-44ac-a7dd-dc563e084ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_highlighted_df(df):\n",
    "    return df.style.highlight_max(subset = ['value_over_replacement_player',\n",
    "                                                    'player_efficiency_rating',\n",
    "                                                    'W/L%',\n",
    "                                                    'win_shares_per_48_minutes',\n",
    "                                                    'usage_percentage',\n",
    "                                                    'free_throw_attempt_rate',\n",
    "                                                    'offensive_box_plus_minus',\n",
    "                                                    'PTS',\n",
    "                                                    'Share Prediction'], color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86118bda-b4e4-46d9-b3a5-ae37189298e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train on historical data, predict on 2022 data\n",
    "forecast_X_train_df, forecast_y_train_df, forecast_X_test_df = prep_train_test(df=master_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f56ad",
   "metadata": {},
   "source": [
    "NOTE: **VORP** (value_over_replacement_player) metric for 2022 candidates has been adjusted as a projection considering the games left in the season. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09a6df",
   "metadata": {},
   "source": [
    "### Model 1: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6fde9-f65f-4c52-942e-ea7eb13b15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fedea2-80de-4922-a6e7-0e5d71e094a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best xgb model\n",
    "xgb_model, xgb_mvp_race_forecast = fit_forecast_model(regressor = XGBRegressor(\n",
    "                                            n_estimators=16,\n",
    "                                            max_depth=5,\n",
    "                                            learning_rate=0.2745))\n",
    "\n",
    "# 16 5, 0.2745\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725043a-dfef-41e6-bd13-d6ccfbad590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_highlighted_df(df=xgb_mvp_race_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc44ba48-2194-4090-8215-c2e40c8e704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_shap_values(model= xgb_model, mvp_race=xgb_mvp_race_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f9591",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5425b87-c093-4c02-93ee-ab6e8a0be68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2aa95a-5305-48a0-97df-fcadd27ad4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best random forest model\n",
    "rf_model, rf_mvp_race_forecast = fit_forecast_model(regressor = RandomForestRegressor(n_estimators = 23, \n",
    "                                                  random_state = 0, \n",
    "                                                  max_depth=7, \n",
    "                                                  min_samples_leaf=1,\n",
    "                                                  min_samples_split=2)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78291d2d-1167-4d81-84ee-8def3b7af919",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_highlighted_df(df=rf_mvp_race_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74899d03-12f9-40e4-be35-61c6760ceb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_shap_values(model = rf_model, mvp_race= rf_mvp_race_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec309c18",
   "metadata": {},
   "source": [
    "#### Model 3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e3cf6-cd15-4f96-b48a-72fd62d8d939",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgbm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741432f4-8765-421e-bd80-1ac7011829ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best LightGBM model\n",
    "lgbm_model, lgbm_mvp_race_forecast = fit_forecast_model(\n",
    "                                                regressor = LGBMRegressor(\n",
    "                                                                    n_estimators=23,\n",
    "                                                                    max_depth=4,\n",
    "                                                                    learning_rate=0.15,\n",
    "                                                                    num_leaves=28,\n",
    "                                                                    boosting_type='goss',\n",
    "                                                                    random_state = 0,\n",
    "                                           ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564ec11-6afe-4901-bb1f-749f9f84abf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_highlighted_df(df=lgbm_mvp_race_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ecf22-5634-4c56-bbc0-8c719dc0ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_shap_values(model = lgbm_model, mvp_race= lgbm_mvp_race_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba233ebf-797c-4c4d-8398-3194f6b3b276",
   "metadata": {},
   "source": [
    "#### MVP Prediction Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648f17d-425b-4fb8-b4d6-54706d392c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_tables = [xgb_mvp_race_forecast, lgbm_mvp_race_forecast, rf_mvp_race_forecast]\n",
    "model_names = ['XGBoost', 'LightGBM', 'Random Forest']\n",
    "\n",
    "tables = []\n",
    "for name, forecast_table in zip(model_names, forecast_tables):\n",
    "    player_sub = forecast_table.head(3)[['Player']]\n",
    "    player_sub['Rank'] = ['1st Place','2nd Place','3rd Place']\n",
    "    player_sub2 = player_sub.T.reset_index(drop=True)\n",
    "    player_sub2.columns = player_sub2.iloc[1]\n",
    "    player_sub2.drop(player_sub2.tail(1).index,inplace=True)\n",
    "\n",
    "    share_sub = forecast_table.head(5)[['Share Prediction']]\n",
    "    share_sub['Rank'] = ['1st Place Share','2nd Place Share','3rd Place Share']\n",
    "    \n",
    "    share_sub2 = share_sub.T.reset_index(drop=True)\n",
    "    share_sub2.columns = share_sub2.iloc[1]\n",
    "    share_sub2.drop(share_sub2.tail(1).index,inplace=True)\n",
    "\n",
    "    merged_df = pd.concat([player_sub2, share_sub2], axis=1).sort_index(axis=1)\n",
    "    merged_df['Model'] = name\n",
    "    tables.append(merged_df)\n",
    "    \n",
    "final_summary_table = pd.concat(tables)\n",
    "# shift column 'Name' to first position\n",
    "first_column = final_summary_table.pop('Model')\n",
    "# first_column) function\n",
    "final_summary_table.insert(0, 'Model', first_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31711b1-dc2a-4340-91cc-1f2ff8590d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93447231-dd13-4461-8f49-195ce4fd4849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated 4/15/2022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
